# -*- coding: utf-8 -*-
"""

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k4wLQUhbu-lPACn4xyhULqhWcMibIzj3
"""

!pip install selenium
!apt-get update
!apt install chromium-chromedriver
!cp /usr/lib/chromium-browser/chromedriver /usr/bin

import sys
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')
from selenium import webdriver
from tqdm.notebook import tqdm as tqdm
import pandas
import json
import pprint

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')

wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)
wd.get("https://www.autoscout24.it/lst?sort=age&desc=1&fuel=E&ustate=N%2CU&size=20&page=1&cy=I")

# Commented out IPython magic to ensure Python compatibility.
import time
wd.set_window_size(1920, 1080)
time.sleep(2)
wd.save_screenshot('screenshot.png')

# %pylab inline
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
img=mpimg.imread('/content/screenshot.png')
imgplot = plt.imshow(img)
plt.show()

def loop_offer_pages(x):

  id = x.get_attribute("data-guid") #guid dell'annuncio
  try:
    page = x.find_element_by_css_selector(".cldt-summary-titles > a").get_attribute("href") #pagina dell'annauncio
    vehicle = x.find_element_by_css_selector(".cldt-summary-makemodel.sc-font-bold.sc-ellipsis").text
    price = x.find_elements_by_css_selector("""[data-item-name="price"]""")[0].text # 23 restituisce se c'è una rata, iva dedicibile etc
    vehicle_data = x.find_elements_by_css_selector(".cldt-summary-vehicle-data")[0].text.split("\n")
  except:
    page = ""
    vehicle = ""
    price = ""
    vehicle_data = ""
  try:
    vehicle_usr_desc = x.find_elements_by_css_selector(".cldt-summary-version")[0].text
  except:
     vehicle_usr_desc = ""
  seller_list = x.find_elements_by_css_selector("""[data-item-name="seller"]""")[0].text.split("\n")
  if seller_list[1].find('(') != -1:
    del seller_list[1]
  seller = seller_list[0]
  seller_country = seller_list[1]
  seller_address = seller_list[2]
  return {
      'id_annuncio': id,
      'link_annuncio': page,
      'vehicle': vehicle,
      'vehicle_user_desc' : vehicle_usr_desc,
      'asking_price' : price,
      'vehicle_data' : vehicle_data,
      'seller' : seller,
      'country' : seller_country,
      'address' : seller_address,
      }

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import numpy as np
import requests
import urllib.request
import os

path_offers_page = 'screenshot/offers_page/'
path_single_offers_page = 'screenshot/single_offer_page/'
path_offer_img = 'screenshot/single_offer_page/offer_img/'

try:
 os.makedirs(path_offers_page)
 os.makedirs(path_single_offers_page)
 os.makedirs(path_offer_img)
except:
  pass

#create blank list to enclose all offers page results
output_scraping = []

for i in tqdm(range(1,21)): #20 is hard coded :(
  url = "https://www.autoscout24.it/lst?sort=age&desc=1&fuel=E&ustate=N%2CU&size=20&page=" + str(i) + "&cy=I"
  print(url)
  time.sleep(abs(np.random.normal(2,2)))
  wd.set_window_size(1920,1080)
  wd.get(url)
  try:
    WebDriverWait(wd, 15).until(
        EC.element_to_be_clickable((By.CSS_SELECTOR, "a.active")) #loads bottom bar, which is the last to be loaded in chromium
    )
  except:
    continue
  wd.save_screenshot(path_offers_page + str(i) + '.png')
  lista_annunci = wd.find_elements_by_css_selector(".cl-list-element.cl-list-element-gap")
  for x in lista_annunci:
    output_scraping.append(loop_offer_pages(x))
  #if len(lista_annunci) < 20: #exit if there are less than 20 offers on 1 page
  #  break

print(len(output_scraping))

import json
export_output_scraping = open('export_output_scraping.json', mode='w+')
export_output_scraping.write(json.dumps(output_scraping, indent=3))
export_output_scraping.close()

details_raw = []
details_value = wd.find_elements_by_css_selector("""[data-item-name="car-details"] >* dd""")
details_field = wd.find_elements_by_css_selector("""[data-item-name="car-details"] >* dt""")
for i in range(0,len(details_field)):
  details_raw_field = details_field[i].text
  details_raw_value = details_value[i].text
  if details_raw_value == "":
    details_raw_value = "Sì"
  details_raw.append(details_raw_field)
  details_raw.append(details_raw_value)

it = iter(details_raw) 
details = dict(zip(it, it)) 
print(details)

def loop_single_offer_pages(k):
  url = k['link_annuncio']
  print (url)
  wd.set_window_size(1920,1080)
  wd.get(url)

  wd.save_screenshot(path_single_offers_page + k['id_annuncio']+ ".png")
  try:
    user_description = wd.find_elements_by_css_selector("""[data-type="description"]""")[0].text
  except:
    user_description = ""

  try:
    equipment_raw = wd.find_elements_by_css_selector(".cldt-equipment-block span")
    equipment = []
    for l in equipment_raw:
      equipment.append(l.text)
    print (equipment)
  except:
    equipment = ""


  details_raw = []
  details_value = wd.find_elements_by_css_selector("""[data-item-name="car-details"] >* dd""")
  details_field = wd.find_elements_by_css_selector("""[data-item-name="car-details"] >* dt""")
  for m in range(0,len(details_field)):
    details_raw_field = details_field[m].text
    details_raw_value = details_value[m].text
    if details_raw_value == "":
      details_raw_value = "Sì"
    details_raw.append(details_raw_field)
    details_raw.append(details_raw_value)
  it = iter(details_raw) 
  details = dict(zip(it, it)) 
  print (details)
  
  try:
    vehicle_img = wd.find_element_by_css_selector(".single-picture > img").get_attribute("src")
    print(vehicle_img)
    urllib.request.urlretrieve(vehicle_img, path_offer_img + k['id_annuncio'] + ".jpg")
  except:
    try:
      vehicle_img = wd.find_element_by_css_selector("""[style="order: 0;"] > * > .gallery-picture__image""").get_attribute("src")
      print(vehicle_img)
      urllib.request.urlretrieve(vehicle_img, path_offer_img + k['id_annuncio'] + ".jpg")
    except:
      vehicle_img = open(path_offer_img + k['id_annuncio'] + ".jpg", "w")
  
  return {
      'id_annuncio' : k['id_annuncio'],
      'user_description' : user_description,
      'equipment' : equipment,
      'specs' : details,
      'img' : k['id_annuncio'] + ".jpg"
       }

output_single_offers_scraping = []
import urllib.request

for i in output_scraping:
  output_single_offers_scraping.append(loop_single_offer_pages(i))

print (len(output_single_offers_scraping))

import json
export_output_single_offers_scraping = open('export_output_single_offers_scraping.json', mode='w+')
export_output_single_offers_scraping.write(json.dumps(output_single_offers_scraping, indent=3))
export_output_single_offers_scraping.close()

!zip -r "screenshot.zip" "/content/screenshot/"
