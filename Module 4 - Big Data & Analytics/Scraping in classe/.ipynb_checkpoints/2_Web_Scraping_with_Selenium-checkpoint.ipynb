{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VYfg3I_fSt6e"
   },
   "source": [
    "# WebScraping with Selenium\n",
    "\n",
    "This notebook shows how use selenium to scrape data from Kickstarter.com\n",
    "The scope is only to understand the capabilities of web scraping and prepare a dataset for academic purporse.\n",
    "\n",
    "Let�s begin writing our scraper!\n",
    "\n",
    "We will first install important modules and packages for our Notebook\n",
    "\n",
    "\n",
    "*   Selenium\n",
    "*   Chromium-chromedriver\n",
    "\n",
    "<a href=\"https://colab.research.google.com/drive/1_WyM24eXWf-pdcqJKCcsb1pWwnbEWRi8?authuser=2#scrollTo=VYfg3I_fSt6e\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6E11q1711nmO",
    "outputId": "3d8b6e34-3366-45f9-9498-68fd962b7d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
      "\u001b[K     |████████████████████████████████| 911kB 3.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.24.3)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
      "Get:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release [564 B]\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Get:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
      "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
      "Get:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release.gpg [833 B]\n",
      "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:12 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Ign:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
      "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [185 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:15 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Packages [40.0 kB]\n",
      "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [37.6 kB]\n",
      "Get:17 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [9,012 B]\n",
      "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [862 kB]\n",
      "Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,841 kB]\n",
      "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,398 kB]\n",
      "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [82.2 kB]\n",
      "Get:22 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [977 kB]\n",
      "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,270 kB]\n",
      "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [13.4 kB]\n",
      "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [93.9 kB]\n",
      "Get:26 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [888 kB]\n",
      "Fetched 7,992 kB in 3s (2,354 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-440\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following additional packages will be installed:\n",
      "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
      "Suggested packages:\n",
      "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
      "The following NEW packages will be installed:\n",
      "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
      "  chromium-codecs-ffmpeg-extra\n",
      "0 upgraded, 4 newly installed, 0 to remove and 63 not upgraded.\n",
      "Need to get 75.5 MB of archives.\n",
      "After this operation, 256 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 83.0.4103.61-0ubuntu0.18.04.1 [1,119 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 83.0.4103.61-0ubuntu0.18.04.1 [66.7 MB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 83.0.4103.61-0ubuntu0.18.04.1 [3,378 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 83.0.4103.61-0ubuntu0.18.04.1 [4,294 kB]\n",
      "Fetched 75.5 MB in 4s (21.1 MB/s)\n",
      "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
      "(Reading database ... 144328 files and directories currently installed.)\n",
      "Preparing to unpack .../chromium-codecs-ffmpeg-extra_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-codecs-ffmpeg-extra (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-browser.\n",
      "Preparing to unpack .../chromium-browser_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-browser (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-browser-l10n.\n",
      "Preparing to unpack .../chromium-browser-l10n_83.0.4103.61-0ubuntu0.18.04.1_all.deb ...\n",
      "Unpacking chromium-browser-l10n (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-chromedriver.\n",
      "Preparing to unpack .../chromium-chromedriver_83.0.4103.61-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-chromedriver (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-codecs-ffmpeg-extra (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-browser (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
      "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
      "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
      "Setting up chromium-chromedriver (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-browser-l10n (83.0.4103.61-0ubuntu0.18.04.1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuhZcDh4UHYp"
   },
   "source": [
    "And now we will import some modules on our Notebook\n",
    "\n",
    "\n",
    "1.   sys: to setup the path of chrome driver\n",
    "2.   selenium: to emulate the user behaviour\n",
    "3.   pandas: to work with data\n",
    "4.   tqdm: to show a progress bar in our notebook\n",
    "5.   json: to work with json format\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YRt5yEXxA-jW"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pandas\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ksyefP35VQc2"
   },
   "source": [
    "First we need to set the options for the ghost browser.\n",
    "The most important is `--headless` because we are in a \"cloud\" ntotebook. In our local notebook we can remove the `--headless` option.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DTfvdy_gBCBU"
   },
   "outputs": [],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0DpumOn7VoFw"
   },
   "source": [
    "`webdriver` is the most importa object in Selenium.\n",
    "With `webdriver` we can start the phantom browser, emulate the user navigation and scrape our data. \n",
    "\n",
    "Let�s now create a new instance of google chrome.\n",
    "\n",
    "\n",
    "We will navitage to page by a `get` request. With http we can do a get or a post (or others but they are not important for us): https://www.w3schools.com/tags/ref_httpmethods.asp \n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "wd.get(\"https://www.kickstarter.com/discover/advanced?sort=magic&ref=nav_search&page=1\")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "D6MLvqs9BIzI",
    "outputId": "f4773fb6-9289-431a-c9e9-2ddfdb4f3980"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: use options instead of chrome_options\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
    "wd.get(\"https://www.kickstarter.com/discover/advanced?sort=magic&ref=nav_search&page=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p3Sbfud-WbV-"
   },
   "source": [
    "Take a look to the screenshot from our phantom browser.\n",
    "\n",
    "Note:\n",
    "- la language and the locale: It is en_US!\n",
    "- the screen ration: is it the same of our notebook?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "iBCZSC4dWfKW",
    "outputId": "a8671033-335d-463d-efc4-8d14b1b309df"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-05e2e98949ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_screenshot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'screenshot.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pylab inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wd' is not defined"
     ]
    }
   ],
   "source": [
    "wd.save_screenshot('screenshot.png')\n",
    "\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('/content/screenshot.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kRr2IAQsa1s_"
   },
   "source": [
    "Let's try to extract some information from the page\n",
    "\n",
    "\n",
    "\n",
    "`title` contains the title of our page.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "X033nUzra6uq",
    "outputId": "c1824e3a-30f4-470f-e225-485d9ea2531e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discover Projects — Kickstarter\n"
     ]
    }
   ],
   "source": [
    "print(wd.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C2FL7PA0jXdP"
   },
   "source": [
    "### First exercise with *Selenium*\n",
    "\n",
    "Try it yourself... Print the contents of the page on the screen!\n",
    "\n",
    "Complete the code and annotate the different behaviour. Try to use the attributes/methods applied to `wd`\n",
    "\n",
    "- `page_source`\n",
    "- `find_element_by_tag_name(\"body\")`\n",
    "- `find_element_by_tag_name(\"body\").text`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 135
    },
    "colab_type": "code",
    "id": "wkPbJsAPj19o",
    "outputId": "0893f6e0-b6a7-44c4-a6ea-2f3134d63bca"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-c6d0bb5853b2>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(....)\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zK7Cf_mradiL"
   },
   "source": [
    "### How do we extract the values inside a page with CSS Selector?\n",
    "\n",
    "Selenium has a method called `find_elements_by_css_selector`.\n",
    "\n",
    "We will pass our CSS Selector into this method and get a list of selenium elements. Once we have the element, we can extract the text inside it using the `text` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFuRVKIdbWN3"
   },
   "outputs": [],
   "source": [
    "list_h3 = wd.find_elements_by_css_selector(\"h3\")\n",
    "print(len(list_h3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cRPP5xUrbwcE"
   },
   "outputs": [],
   "source": [
    "print(list_h3[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bAtLMeKVb8Wp"
   },
   "source": [
    "### Exercise on *find_elements_by_css_selector*\n",
    "\n",
    "Try to export the list of `p` elements and show the content of the first element.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6_4-y31fcEYq"
   },
   "outputs": [],
   "source": [
    "list_p = wd......(\"...\")\n",
    "print(len(list_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A1ETBqlPcQhl"
   },
   "source": [
    "# Project List from Kickstarter\n",
    "\n",
    "Let's begin to download the list of projects.\n",
    "\n",
    "The list of projects is defined by the css selection rule\n",
    "`#projects_list > div > div.js-react-proj-card`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_V1hNO9ZcJy6"
   },
   "outputs": [],
   "source": [
    "list_projects = wd.find_elements_by_css_selector(\"#projects_list > div > div.js-react-proj-card\")\n",
    "print(len(list_projects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k_fSFWX0cktI"
   },
   "source": [
    "Gread! We find 12 project!\n",
    "\n",
    "Now, we will extract the attribute from each single element.\n",
    "The scope is to create one dict for each project in the list with the attribute:\n",
    "\n",
    "\n",
    "1.   url\n",
    "2.   title\n",
    "3.   description\n",
    "4.   category\n",
    "5.   location\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1J2xAL6qcj9-"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "detail_projects = []\n",
    "for project in list_projects:\n",
    "    title = project.find_elements_by_css_selector(\"h3\")[0].text\n",
    "    url = project.find_elements_by_css_selector(\"a\")[0].get_attribute(\"href\")\n",
    "    if(len(project.find_elements_by_css_selector(\".pb3 a\")) > 5):\n",
    "      description = project.find_elements_by_css_selector(\".mb3 p\")[0].text\n",
    "      category = project.find_elements_by_css_selector(\".pb3 a\")[4].text\n",
    "      location = project.find_elements_by_css_selector(\".pb3 a\")[5].text\n",
    "    else:\n",
    "      description = project.find_elements_by_css_selector(\".mb3 p\")[0].text\n",
    "      category = project.find_elements_by_css_selector(\".pb3 a\")[3].text\n",
    "      location = project.find_elements_by_css_selector(\".pb3 a\")[4].text\n",
    "    project_id = project.get_attribute(\"data-pid\")\n",
    "\n",
    "    detail_projects.append({'url': url,\n",
    "                            'title': title,\n",
    "                            'description': description,\n",
    "                            'category': category,\n",
    "                            'location': location,\n",
    "                            'project_id': project_id})\n",
    "\n",
    "len(detail_projects)\n",
    "pprint.pprint(detail_projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Sn0txryfR4c"
   },
   "source": [
    "Now let's try downloading all the ads on the front page...\n",
    "and then move on to the second.\n",
    "\n",
    "First we define a `parse_project` function to make the code cleaner and to reuse the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tD3KLUrIfTJd"
   },
   "outputs": [],
   "source": [
    "def parse_project(project):\n",
    "  project_id = project.get_attribute(\"data-pid\")\n",
    "  title = \"\"\n",
    "  description = \"\"\n",
    "  category = \"\"\n",
    "  location = \"\"\n",
    "  try:\n",
    "    title = project.find_elements_by_css_selector(\"h3\")[0].text\n",
    "    url = project.find_elements_by_css_selector(\"a\")[0].get_attribute(\"href\")\n",
    "    if(len(project.find_elements_by_css_selector(\".pb3 a\")) > 5):\n",
    "      description = project.find_elements_by_css_selector(\".mb3 p\")[0].text\n",
    "      category = project.find_elements_by_css_selector(\".pb3 a\")[4].text\n",
    "      location = project.find_elements_by_css_selector(\".pb3 a\")[5].text\n",
    "    else:\n",
    "      description = project.find_elements_by_css_selector(\".mb3 p\")[0].text\n",
    "      category = project.find_elements_by_css_selector(\".pb3 a\")[3].text\n",
    "      location = project.find_elements_by_css_selector(\".pb3 a\")[4].text\n",
    "  except:\n",
    "    pass\n",
    "  return {'url': url,\n",
    "          'title': title,\n",
    "          'description': description,\n",
    "          'category': category,\n",
    "          'location': location,\n",
    "          'project_id': project_id}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SR-xG0FIgf7u"
   },
   "source": [
    "Here's how to download the first two pages of projects..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfWSS_33fbZg"
   },
   "outputs": [],
   "source": [
    "detail_projects = []\n",
    "for num in tqdm(range(1,3)):\n",
    "  wd.get(f\"https://www.kickstarter.com/discover/advanced?sort=popularity&ref=nav_search&page={num}\")\n",
    "  wd.save_screenshot(f'screenshot_{num}.png')\n",
    "  list_projects = wd.find_elements_by_css_selector(\"#projects_list > div > div.js-react-proj-card\")\n",
    "  for project in list_projects:\n",
    "    detail_projects.append(parse_project(project))\n",
    "\n",
    "print(len(detail_projects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HbjVFLOOgnNx"
   },
   "source": [
    "Have you seen the bookstore **tqdm**!\n",
    "Find at this link all the documentation **https://github.com/tqdm/tqdm**:\n",
    "is very useful to make our notebook more nice..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S9MsWLutg4Oi"
   },
   "source": [
    "### How to end scraping?\n",
    "Problem: When do we stop?\n",
    "\n",
    "There are several ways. Some simpler and some more advanced:\n",
    "- We can search inside the page for the ad number and divide it by 12\n",
    "- We can check the status of the request (if (status_code == 200):... for a list of possible http status codes please check https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- We can check the number of ads found (if > 0...)\n",
    "- Other more advanced techniques...\n",
    "\n",
    "For example, in our case, let's go to verify the presence, or not, of the *Load more* button inside the page. If present, we continue scraping, otherwise we stop.\n",
    "\n",
    "Actually, we can also combine more than one of these techniques.\n",
    "\n",
    "For this exercise we will just download the first 10 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nkofmsCGgwQA"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "detail_projects = []\n",
    "for num in tqdm(range(1,10)):\n",
    "  time.sleep(1)\n",
    "  wd.get(f\"https://www.kickstarter.com/discover/advanced?sort=popularity&ref=nav_search&page={num}\")\n",
    "  #wd.save_screenshot(f'screenshot_{num}.png')\n",
    "  list_projects = wd.find_elements_by_css_selector(\"#projects_list > div > div.js-react-proj-card\")\n",
    "  for project in list_projects:\n",
    "    detail_projects.append(parse_project(project))\n",
    "\n",
    "print(len(detail_projects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TqxsicNNovfy"
   },
   "source": [
    "# Pandas and data processing\n",
    "\n",
    "**Well!**\n",
    "We're starting to see another amazing library for working with data!\n",
    "\n",
    "It's **pandas**: *Python library for data analysis*.\n",
    "\n",
    "Basically, with pandas we can manipulate a data set or a historical series in Python.\n",
    "\n",
    "For now, we start to give a couple of concepts.\n",
    "\n",
    "Pandas is based on two types of data: **Series** and **DataFrame**:\n",
    "- `Series` represents a list of data\n",
    "- `DataFrame` represent a data set in tabular format\n",
    "\n",
    "Each column of a `DataFrame` is a `Series`.\n",
    "\n",
    "We can create a `DataFrame` using the `pd.DataFrame` method by passing our dictionary as an input parameter.\n",
    "\n",
    "A `DataFrame` pandas can be easily exported in *CSV*, *Excel*, ...\n",
    "\n",
    "For more information about `Pandas` see\n",
    "\n",
    "https://pandas.pydata.org/getting_started.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MumFgyNypoBo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds_detail_projects = pd.DataFrame(detail_projects)\n",
    "ds_detail_projects.set_index(\"project_id\")\n",
    "ds_detail_projects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwW7Sj7irFDT"
   },
   "source": [
    "The `.info()` method provides an indication of the structure and data of the `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tFbyPwcrNY4"
   },
   "outputs": [],
   "source": [
    "ds_detail_projects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lUw4-_BrQDh"
   },
   "outputs": [],
   "source": [
    "ds_detail_projects.to_csv('ds_projects.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AXdgP8t3q_A-"
   },
   "source": [
    "# Kickstarter Project pages ###\n",
    "\n",
    "Now, the goal is to navigate and download the details of each project and pictures of the houses.\n",
    "\n",
    "**Pandas** provides the *.read_csv* method that allows you to upload in CSV format files within a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yVnUyfGsvcac"
   },
   "outputs": [],
   "source": [
    "# open csv file\n",
    "import pandas as pd\n",
    "ds_detail_projects = pd.read_csv(\"ds_projects.csv\", index_col=\"project_id\")\n",
    "ds_detail_projects.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8VaXQ52Kv2am"
   },
   "source": [
    "***For each project we go to the link... how do you think we do it?***\n",
    "\n",
    "Let's try the first 5 projects.\n",
    "\n",
    "\n",
    "\n",
    "These days most of the web apps are using AJAX techniques. When a page is loaded by the browser, the elements within that page may load at different time intervals. Using waits, we can stop our scraping and wait the loading of a element.\n",
    "\n",
    "Selenium Webdriver provides two types of waits - implicit & explicit. An explicit wait makes WebDriver wait for a certain condition to occur before proceeding further with execution. An implicit wait makes WebDriver poll the DOM for a certain amount of time when trying to locate an element.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7RJTIyFfv-Ig"
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "details = []\n",
    "for project_id, project in ds_detail_projects.head().iterrows():\n",
    "    time.sleep(10)\n",
    "    link = project[\"url\"]\n",
    "    print(link)\n",
    "    wd.set_window_size(1920, 1080)\n",
    "    wd.get(link)\n",
    "    try:\n",
    "      WebDriverWait(wd, 10).until(\n",
    "          EC.element_to_be_clickable((By.ID, \"back-project-button\"))\n",
    "      )\n",
    "    except:\n",
    "      continue\n",
    "\n",
    "    wd.save_screenshot(f'screenshot_{project_id}.png')\n",
    "    backers = wd.find_elements_by_css_selector(\".type-16.dark-grey-500\")[0].text\n",
    "    goal = wd.find_elements_by_css_selector(\".ksr-green-500\")[0].text\n",
    "    pledged = wd.find_elements_by_css_selector(\"span.money\")[1].text\n",
    "    details.append({'project_id': project_id,\n",
    "                    'backers': backers,\n",
    "                    'goal': goal,\n",
    "                    'pledged': pledged})\n",
    "  \n",
    "len(details)\n",
    "pprint.pprint(details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xf7bDTWTxLlf"
   },
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "details = []\n",
    "for project_id, project in tqdm(ds_detail_projects.iterrows(), total=ds_detail_projects.shape[0]):\n",
    "    time.sleep(1)\n",
    "    link = project[\"url\"]\n",
    "    backers = 0\n",
    "    goal = 0\n",
    "    pledged = 0\n",
    "    #print(link)\n",
    "    try:\n",
    "      wd.set_window_size(1920, 1080)\n",
    "      wd.get(link)\n",
    "      try:\n",
    "        WebDriverWait(wd, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"back-project-button\"))\n",
    "        )\n",
    "      except:\n",
    "        continue\n",
    "\n",
    "      wd.save_screenshot(f'screenshot_{project_id}.png')\n",
    "      backers_list = wd.find_elements_by_css_selector(\".type-16.dark-grey-500\")\n",
    "      goal_list = wd.find_elements_by_css_selector(\".ksr-green-500\")\n",
    "      pledged_list = wd.find_elements_by_css_selector(\"span.money\")\n",
    "      if(len(backers_list) > 0):\n",
    "        backers = backers_list[0].text\n",
    "      if(len(goal_list) > 0):\n",
    "        goal = goal_list[0].text\n",
    "      if(len(pledged_list) > 1):\n",
    "        pledged = pledged_list[1].text\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "    details.append({'project_id': project_id,\n",
    "                    'backers': backers,\n",
    "                    'goal': goal,\n",
    "                    'pledged': pledged})\n",
    "  \n",
    "print(len(details))\n",
    "#pprint.pprint(details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nmOdNznWXKtj"
   },
   "outputs": [],
   "source": [
    "len(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fcfGcK4O4R2-"
   },
   "source": [
    "Store the data with *pandas*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4xik7JIr4J-n"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds_details = pd.DataFrame(details)\n",
    "ds_details.set_index(\"project_id\")\n",
    "ds_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBkNRigl4b9G"
   },
   "outputs": [],
   "source": [
    "ds_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YSlNICg94fKj"
   },
   "outputs": [],
   "source": [
    "ds_details.to_csv(\"ds_project_details.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dJdurd8345Jp"
   },
   "source": [
    "# Kickstarter Project images\n",
    "\n",
    "\n",
    "Now we're going to download Kickstarter images for each project.\n",
    "\n",
    "Our goal is to create a dataset of images and a `Dataframe` composed by:\n",
    "- `project_id`\n",
    "- `image_id`\n",
    "\n",
    "We will use the library `requests`.\n",
    "\n",
    "The `requests` library is python library for making HTTP requests.\n",
    "It abstracts the complexities of making requests behind a simple API so that you can focus on interacting with services and consuming data in your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1cy5Jzt6ab-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "detail_projects = []\n",
    "list_images = []\n",
    "\n",
    "for num in tqdm(range(1,100)):\n",
    "  time.sleep(1)\n",
    "  wd.get(f\"https://www.kickstarter.com/discover/advanced?sort=magic&ref=nav_search&page={num}\")\n",
    "  list_projects = wd.find_elements_by_css_selector(\"#projects_list > div > div.js-react-proj-card\")\n",
    "  for project in list_projects:\n",
    "    try:\n",
    "      project_id = project.get_attribute(\"data-pid\")\n",
    "      src = project.find_element_by_css_selector(\"a img\").get_attribute(\"src\")\n",
    "      list_images.append({\"project_id\": project_id,\n",
    "                          \"img_file\": \"img_\" + str(project_id) + \".jpg\"})\n",
    "      img_file = requests.get(src, stream=True)\n",
    "      if img_file.status_code == 200:\n",
    "        with open(\"/content/images/img_\" + str(project_id) + \".jpg\", 'wb') as f:\n",
    "          f.write(img_file.content)\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wy5AJ3iUj-DO"
   },
   "outputs": [],
   "source": [
    "print(len(list_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BSPk4TWtAvWj"
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('/content/images/img_142016465.jpg')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oq-mP-v8LZl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds_images = pd.DataFrame(list_images)\n",
    "ds_images.set_index(\"project_id\")\n",
    "ds_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1A0HPUPhmdT"
   },
   "outputs": [],
   "source": [
    "ds_images.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2CLUnkOW8O0Q"
   },
   "outputs": [],
   "source": [
    "ds_images.to_csv(\"ds_images.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0F53Zz7JRN2"
   },
   "outputs": [],
   "source": [
    "!zip -r \"/content/images.zip\" \"/content/images/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_f5pD019XW6"
   },
   "source": [
    "# API\n",
    "\n",
    "Let's see how to use the **requests** library to hook APIs provided by our suppliers or colleagues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuDgoTW29jH_"
   },
   "source": [
    "## Crarifai\n",
    "\n",
    "Let's try the services provided by Clarifai to increase the data we have available.\n",
    "\n",
    "\n",
    "First, we need to install the `crarifai` python library.\n",
    "For more details, please visit https://github.com/Clarifai/clarifai-python\n",
    "\n",
    "To install the API client:\n",
    "\n",
    "\n",
    "```\n",
    "pip install clarifai\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WgBUGy519fzQ"
   },
   "outputs": [],
   "source": [
    "!pip install clarifai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7O5yiMD-BHm"
   },
   "outputs": [],
   "source": [
    "from clarifai.rest import ClarifaiApp\n",
    "\n",
    "# setup your key!!!\n",
    "clarifai_key = \"41a0bb727c0c462d8cd09aa359fa9649\"\n",
    "app = ClarifaiApp(api_key=clarifai_key)\n",
    "\n",
    "# and use the general model\n",
    "model = app.public_models.general_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vi3vpTjo-JlU"
   },
   "source": [
    "We will use the `predict_by_filename` method to obtain the **concepts** within the page.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kv3BOOAG-PAt"
   },
   "outputs": [],
   "source": [
    "response = model.predict_by_filename(\"/content/images/img_142016465.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gNKcVLk-bU-"
   },
   "source": [
    "What type of data does that give us back?\n",
    "Let's have a look!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUKxISg_-kht"
   },
   "outputs": [],
   "source": [
    "pprint.pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0vFofm3-o67"
   },
   "source": [
    "And get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bLXAR3GS-oYX"
   },
   "outputs": [],
   "source": [
    "if(response['status']['description'] == \"Ok\"):\n",
    "    for concept in response[\"outputs\"][0][\"data\"][\"concepts\"]:\n",
    "        name = concept[\"name\"]\n",
    "        value = concept[\"value\"]\n",
    "        print(name + \" \" + str(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0RiAZbNkB5Au"
   },
   "source": [
    "Now let's go and identify all the concepts for each image of each project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uu3J01GhB_w4"
   },
   "outputs": [],
   "source": [
    "ds_images = pd.read_csv(\"ds_images.csv\", index_col=\"project_id\")\n",
    "\n",
    "img_details = []\n",
    "for project_id, image in tqdm(ds_images.iterrows(), total=ds_images.shape[0]):\n",
    "  try:\n",
    "    response = model.predict_by_filename(\"/content/images/\" + image['img_file'])\n",
    "    if(response['status']['description'] == \"Ok\"):\n",
    "      for concept in response[\"outputs\"][0][\"data\"][\"concepts\"]:\n",
    "          name = concept[\"name\"]\n",
    "          value = concept[\"value\"]\n",
    "          img_details.append({\n",
    "            \"project_id\": project_id,\n",
    "            \"image\": image['img_file'],\n",
    "            \"name\": name,\n",
    "            \"value\": value\n",
    "          })\n",
    "  except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(len(img_details))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5nIUezSrDTKK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds_img_details = pd.DataFrame(img_details)\n",
    "ds_img_details.set_index(\"image\")\n",
    "ds_img_details.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXJF8-Q4ljK7"
   },
   "outputs": [],
   "source": [
    "ds_img_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WR4kQBsDXwx"
   },
   "outputs": [],
   "source": [
    "ds_img_details.to_csv('ds_img_details.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kt_AIhQM-6zi"
   },
   "source": [
    "# Geocoding\n",
    "\n",
    "What's geocoding?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tBcxapgb_lGp"
   },
   "source": [
    "Let's try to geolocalize the projects..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B4IO9haO_o7W"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "address = \"New Orleans, LA\"\n",
    "key = \"r3xgNwBAviBMdOj4Op90kvyy2iO1CDGz\"\n",
    "geocode_url = f\"http://www.mapquestapi.com/geocoding/v1/address?key={key}&location={address}\"\n",
    "response = requests.get(geocode_url)\n",
    "\n",
    "import json\n",
    "geo = json.loads(response.text)\n",
    "pprint.pprint(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LRQ24oZf_0XB"
   },
   "outputs": [],
   "source": [
    "print(geo['results'][0]['locations'][0]['latLng']['lat'])\n",
    "print(geo['results'][0]['locations'][0]['latLng']['lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GQNKNIi1988g"
   },
   "outputs": [],
   "source": [
    "ds_projects = pd.read_csv(\"ds_projects.csv\", index_col=\"project_id\")\n",
    "ds_projects.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feuWng0zDudp"
   },
   "outputs": [],
   "source": [
    "ds_projects = pd.read_csv(\"ds_projects.csv\", index_col=\"project_id\")\n",
    "\n",
    "import time\n",
    "project_location = []\n",
    "for project_id, project in tqdm(ds_projects.iterrows(), total=ds_projects.shape[0]):\n",
    "  address = project['location']\n",
    "  if(address is None or address == NaN):\n",
    "    print(str(project_id) + \"- \" + project['location'])\n",
    "  else:\n",
    "    key = \"r3xgNwBAviBMdOj4Op90kvyy2iO1CDGz\"\n",
    "    try:\n",
    "      geocode_url = f\"http://www.mapquestapi.com/geocoding/v1/address?key={key}&location={address}\"\n",
    "      response = requests.get(geocode_url)\n",
    "      if(response.status_code == 200):\n",
    "        geo = json.loads(response.text)\n",
    "        lat = geo['results'][0]['locations'][0]['latLng']['lat']\n",
    "        lng = geo['results'][0]['locations'][0]['latLng']['lng']\n",
    "        project_location.append({\n",
    "              \"project_id\": project_id,\n",
    "              \"lat\": lat,\n",
    "              \"lng\": lng\n",
    "            })\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "    \n",
    "\n",
    "print(len(project_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KdlXXE24E9Es"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds_project_location = pd.DataFrame(project_location)\n",
    "ds_project_location.set_index(\"project_id\")\n",
    "ds_project_location.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "abHeZZM0mXmL"
   },
   "outputs": [],
   "source": [
    "ds_project_location.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sg8TZopsFC3b"
   },
   "outputs": [],
   "source": [
    "ds_project_location.to_csv('ds_project_location.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Web_Scraping_with_Selenium.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
